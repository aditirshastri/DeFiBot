{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da8cd2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from wikipedia) (4.9.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from wikipedia) (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.12.5)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->wikipedia) (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a1bfe02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<WikipediaPage 'Decentralized finance'>, <WikipediaPage 'Decentralized computing'>, <WikipediaPage 'Decentralized autonomous organization'>, <WikipediaPage 'Decentralized network 42'>, <WikipediaPage 'Decentralization'>, <WikipediaPage 'Definition of anarchism and libertarianism'>, <WikipediaPage 'Definitions of fascism'>, <WikipediaPage 'Definition of terrorism'>, <WikipediaPage 'Decentralised system'>, <WikipediaPage '0x (decentralized exchange infrastructure)'>, <WikipediaPage 'Decentralized application'>]\n"
     ]
    }
   ],
   "source": [
    "# EXTRACTS THE DATA FROM WIKIPEDIA (we can change this to telegram or )\n",
    "\n",
    "import pandas as pd\n",
    "import wikipedia\n",
    "\n",
    "\n",
    "def filter(titles):\n",
    "    \"\"\"\n",
    "    Get the titles which are related to curve wars, given a list of titles\n",
    "    \"\"\"\n",
    "    titles = [title for title in titles if 'defi' in title.lower() or 'decentralize' in title.lower()]\n",
    "\n",
    "    return titles\n",
    "\n",
    "\n",
    "def get_wiki_page(title):\n",
    "    \"\"\"\n",
    "    Get the wikipedia page given a title\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return wikipedia.page(title)\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return wikipedia.page(e.options[0])\n",
    "    except wikipedia.exceptions.PageError as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "def recursively_find_all_pages(titles, titles_so_far=set()):\n",
    "    \"\"\"\n",
    "    Recursively find all the pages that are linked to the Wikipedia titles in the list\n",
    "    \"\"\"\n",
    "    all_pages = []\n",
    "\n",
    "    titles = list(set(titles) - titles_so_far)\n",
    "    titles = filter(titles)\n",
    "    titles_so_far.update(titles)\n",
    "    for title in titles:\n",
    "        page = get_wiki_page(title)\n",
    "        if page is None:\n",
    "            continue\n",
    "        all_pages.append(page)\n",
    "\n",
    "        new_pages = recursively_find_all_pages(page.links, titles_so_far)\n",
    "        for pg in new_pages:\n",
    "            if pg.title not in [p.title for p in all_pages]:\n",
    "                all_pages.append(pg)\n",
    "        titles_so_far.update(page.links)\n",
    "    return all_pages\n",
    "\n",
    "pages = recursively_find_all_pages([\"Decentralized Finance\"])\n",
    "print((pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b892b9a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (4.20.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: requests in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.20.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: filelock in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.4.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/eshanaagarwal/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3d9f893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da2fc146",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nlkt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-480c3363b355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnlkt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'punkt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nlkt'"
     ]
    }
   ],
   "source": [
    "import nlkt\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e31c400c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "# SPLITTING THE DATA INTO SECTIONS\n",
    "\n",
    "import re\n",
    "from typing import Set\n",
    "from transformers import GPT2TokenizerFast\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"count the number of tokens in a string\"\"\"\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "def reduce_long(\n",
    "    long_text: str, long_text_tokens: bool = False, max_len: int = 590\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Reduce a long text to a maximum of `max_len` tokens by potentially cutting at a sentence end\n",
    "    \"\"\"\n",
    "    if not long_text_tokens:\n",
    "        long_text_tokens = count_tokens(long_text)\n",
    "    if long_text_tokens > max_len:\n",
    "        sentences = sent_tokenize(long_text.replace(\"\\n\", \" \"))\n",
    "        ntokens = 0\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            ntokens += 1 + count_tokens(sentence)\n",
    "            if ntokens > max_len:\n",
    "                return \". \".join(sentences[:i][:-1]) + \".\"\n",
    "\n",
    "    return long_text\n",
    "\n",
    "discard_categories = ['See also', 'References', 'External links', 'Further reading', \"Footnotes\",\n",
    "    \"Bibliography\", \"Sources\", \"Citations\", \"Literature\", \"Footnotes\", \"Notes and references\",\n",
    "    \"Photo gallery\", \"Works cited\", \"Photos\", \"Gallery\", \"Notes\", \"References and sources\",\n",
    "    \"References and notes\",]\n",
    "\n",
    "\n",
    "def extract_sections(\n",
    "    wiki_text: str,\n",
    "    title: str,\n",
    "    max_len: int = 1000,\n",
    "    discard_categories: Set[str] = discard_categories,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "        Extract the sections of a Wikipedia page, discarding the the references and other low information sections\n",
    "        \"\"\"\n",
    "    if len(wiki_text) == 0:\n",
    "        return []\n",
    "\n",
    "    # find all headings and the coresponding contents\n",
    "    headings = re.findall(\"==+ .* ==+\", wiki_text)\n",
    "    for heading in headings:\n",
    "        wiki_text = wiki_text.replace(heading, \"==+ !! ==+\")\n",
    "    contents = wiki_text.split(\"==+ !! ==+\")\n",
    "    contents = [c.strip() for c in contents]\n",
    "    assert len(headings) == len(contents) - 1\n",
    "\n",
    "    cont = contents.pop(0).strip()\n",
    "    outputs = [(title, \"Summary\", cont, count_tokens(cont) + 4)]\n",
    "\n",
    "    # discard the discard categories, accounting for a tree structure\n",
    "    max_level = 100\n",
    "    keep_group_level = max_level\n",
    "    remove_group_level = max_level\n",
    "    nheadings, ncontents = [], []\n",
    "    for heading, content in zip(headings, contents):\n",
    "        plain_heading = \" \".join(heading.split(\" \")[1:-1])\n",
    "        num_equals = len(heading.split(\" \")[0])\n",
    "        if num_equals <= keep_group_level:\n",
    "            keep_group_level = max_level\n",
    "\n",
    "        if num_equals > remove_group_level:\n",
    "            if (\n",
    "                    num_equals <= keep_group_level\n",
    "            ):\n",
    "                continue\n",
    "        keep_group_level = max_level\n",
    "        if plain_heading in discard_categories:\n",
    "            remove_group_level = num_equals\n",
    "            keep_group_level = max_level\n",
    "            continue\n",
    "        nheadings.append(heading.replace(\"=\", \"\").strip())\n",
    "        ncontents.append(content)\n",
    "        remove_group_level = max_level\n",
    "\n",
    "    # count the tokens of each section\n",
    "    ncontent_ntokens = [\n",
    "        count_tokens(c)\n",
    "        + 3\n",
    "        + count_tokens(\" \".join(h.split(\" \")[1:-1]))\n",
    "        - (1 if len(c) == 0 else 0)\n",
    "        for h, c in zip(nheadings, ncontents)\n",
    "    ]\n",
    "\n",
    "    # Create a tuple of (title, section_name, content, number of tokens)\n",
    "    outputs += [(title, h, c, t) if t < max_len\n",
    "                else (title, h, reduce_long(c, max_len), count_tokens(reduce_long(c, max_len)))\n",
    "                for h, c, t in zip(nheadings, ncontents, ncontent_ntokens)]\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d3867cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/eshanaagarwal/nltk_data'\n    - '/Users/eshanaagarwal/opt/anaconda3/nltk_data'\n    - '/Users/eshanaagarwal/opt/anaconda3/share/nltk_data'\n    - '/Users/eshanaagarwal/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-658b4e0fdb46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#if not(extract_sections(page.content, page.title)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mextract_sections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"heading\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"extract_sections(page.content, page.title)content\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-5e938edfdadc>\u001b[0m in \u001b[0;36mextract_sections\u001b[0;34m(wiki_text, title, max_len, discard_categories)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# Create a tuple of (title, section_name, content, number of tokens)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     outputs += [(title, h, c, t) if t < max_len\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_long\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_long\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 for h, c, t in zip(nheadings, ncontents, ncontent_ntokens)]\n",
      "\u001b[0;32m<ipython-input-6-5e938edfdadc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# Create a tuple of (title, section_name, content, number of tokens)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     outputs += [(title, h, c, t) if t < max_len\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_long\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_long\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 for h, c, t in zip(nheadings, ncontents, ncontent_ntokens)]\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-5e938edfdadc>\u001b[0m in \u001b[0;36mreduce_long\u001b[0;34m(long_text, long_text_tokens, max_len)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mlong_text_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlong_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlong_text_tokens\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlong_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mntokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/eshanaagarwal/nltk_data'\n    - '/Users/eshanaagarwal/opt/anaconda3/nltk_data'\n    - '/Users/eshanaagarwal/opt/anaconda3/share/nltk_data'\n    - '/Users/eshanaagarwal/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for page in pages:\n",
    "    #if not(extract_sections(page.content, page.title)):\n",
    "    res += extract_sections(page.content, page.title)\n",
    "df = pd.DataFrame(res, columns=[\"title\", \"heading\", \"extract_sections(page.content, page.title)content\", \"tokens\"])\n",
    "df = df[df.tokens>40]\n",
    "df = df.drop_duplicates(['title','heading'])\n",
    "df = df.reset_index().drop('index',axis=1) # reset index\n",
    "df.head()\n",
    "df.to_csv('ad_hoc_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "353bb8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Decentralized finance',\n",
       "  'Summary',\n",
       "  'Decentralized finance (DeFi) offers financial instruments without relying on intermediaries such as brokerages, exchanges, or banks by using smart contracts on a blockchain. DeFi platforms allow people to lend or borrow funds from others, speculate on price movements on assets using derivatives, trade cryptocurrencies, insure against risks, and earn interest in savings-like accounts. DeFi uses a layered architecture and highly composable building blocks. Some applications promote high interest rates but are subject to high risk. As of February 2022, the value of assets used in decentralized finance amounted to $200 billion.',\n",
       "  121),\n",
       " ('Decentralized finance',\n",
       "  'History',\n",
       "  'Decentralized exchanges (abbreviated DEXs) as alternative payment ecosystems with new protocols for financial transactions emerged within the framework of decentralized finance, which is part of blockchain technology and FinTech. Unlike centralized cryptocurrency exchanges (CEXs), such as Coinbase, Huobi or Binance, which use order books to match buyers and sellers on the open market and keep crypto assets in an exchange-based wallet, DEXs are non-custodial and leverage the functionality of self-executing smart contracts for peer-to-peer trading, while users retain control of their private keys and funds.Most recently, DEX aggregators have begun to play a more distinctive part in the DEX segment. DEX aggregators form user-centric hubs that compose to several applications and protocols, also providing tools to compare and rate services, which allow users to perform otherwise complex tasks by connecting to several protocols simultaneously. CEXs, DEXs and DEX aggregators are all built on the multi-layered DeFi architecture or components, where each layer serves a well-defined purpose. (See Figure: Multi-layered Architecture of the DeFi Stack). \\nWhile they share common components of the first four layers, such as Settlement layer, Asset layer, Protocol layer and Application layer, DEX aggregators have an additional component  or Aggregator layer, which allows them to connect and interact with other DEXs via smart contracts.The Ethereum blockchain popularized smart contracts, which are the basis of DeFi, in 2017. Other blockchains have since implemented smart contracts.\\nMakerDAO is a prominent lending DeFi platform based on a stablecoin that was established in 2017. It allows users to borrow Dai, a token pegged to the US dollar. Through a set of smart contracts that govern the loan, repayment, and liquidation processes, MakerDAO aims to maintain the stable value of Dai in a decentralized and autonomous manner.In June 2020, Compound Finance started rewarding lenders and borrowers with cryptocurrencies, in addition to typical interest payments to lenders, units of a cryptocurrency called COMP. This token, which is used for running Compound, can also be traded on cryptocurrency exchanges. Other platforms followed suit, leading to \"yield farming\" or \"liquidity mining,\" where speculators shift cryptocurrency assets between pools in a platform and between platforms to maximize their total yield, which includes not only interest and fees but also the value of additional tokens received as rewards.In July 2020, The Washington Post described decentralized finance techniques and the risks involved. In September 2020, Bloomberg said that DeFi made up two-thirds of the cryptocurrency market in terms of price changes and that DeFi collateral levels had reached $9 billion. Ethereum saw a rise in developers during 2020 due to the increased interest in DeFi.DeFi has attracted venture capitalists such as Andreessen Horowitz and Michael Novogratz.The Economist regarded the future of digital finance in 2022 as a \"three-way fight\" between: Big Tech, such as Facebook with its digital wallet; \"big rich countries\" that have been testing their own digital currencies; and software developers \"building all sorts of applications\" to decentralise finance. Handling the risks presented by crypto-assets already valued at $2.5 trillion was a particular challenge for US regulators.',\n",
       "  677),\n",
       " ('Decentralized finance',\n",
       "  'Key characteristics',\n",
       "  'DeFi revolves around decentralized applications, also known as DApps, that perform financial functions on distributed ledgers called blockchains, a technology that was made popular by Bitcoin and has since been adapted more broadly.  Rather than transactions being made through a centralized intermediary such as a cryptocurrency exchange or a traditional securities exchange, transactions are directly made between participants, mediated by smart contract programs. These smart contracts, or DeFi protocols, typically run using open-source software that is built and maintained by a community of developers.DApps are typically accessed through a browser extension or application. For example, MetaMask allows users to directly interact with Ethereum through a digital wallet. Many of these DApps can be linked to create complex financial services. For example, stablecoin holders can lend assets like USD Coin or Dai to a liquidity pool in a borrow/lending protocol like Aave, and allow others to borrow those digital assets by depositing their own collateral. The protocol automatically adjusts interest rates based on the demand for the asset. Some DApps source external (off-chain) data, such as the price of an asset, through blockchain oracles.Additionally, Aave introduced \"flash loans\", which are uncollateralized loans of an arbitrary amount that are taken out and probably paid back within a single blockchain transaction. While there can be legitimate uses for flash loans such as arbitrage, collateral swap, self-liquidation, and unwinding leveraged positions, many exploits of DeFi platforms have used flash loans to manipulate cryptocurrency spot prices.Another DeFi protocol is Uniswap, which is a decentralized exchange (DEX) set up to trade tokens issued on Ethereum. Rather than using a centralized exchange to fill orders, Uniswap pays users to form liquidity pools in exchange for a percentage of the fees that traders earn by swapping tokens in and out of the liquidity pools. Because no centralized party runs Uniswap (the platform is governed by its users), and any development team can use the open-source software, there is no entity to check the identities of the people using the platform and meet KYC/AML regulations. It is not clear what position regulators will take on the legality of such platforms.The table below compares on a ceteris paribus basis the key characteristics of Traditional Finance (TradFi), aka Centralized Finance (CeFi) and Decentralized Finance (DeFi).',\n",
       "  491),\n",
       " ('Decentralized finance',\n",
       "  'Decentralized exchanges',\n",
       "  'Decentralized exchanges (DEX) are a type of cryptocurrency exchange which allows for direct peer-to-peer cryptocurrency transactions to take place online securely and without the need for an intermediary.\\nIn transactions made through decentralized exchanges, the typical third party entities which would normally oversee the security and transfer of assets (e.g. banks, stockbrokers, online payment gateways, government institutions, etc.) are substituted by a blockchain or distributed ledger. Some common methods of operation include the use of smart contracts or order book relaying, although many other variations are possible and with differing degrees of decentralization.Because traders on a decentralized exchange often do not need to transfer their assets to the exchange before executing a trade, decentralized exchanges reduce the risk of theft from hacking of exchanges, but liquidity providers do need to transfer tokens to the decentralized exchange. Decentralized exchanges can also prevent price manipulation or faked trading volume through wash trading, and are more anonymous than exchanges which implement know your customer (KYC) requirements.\\nThere are some signs that decentralized exchanges have been suffering from low trading volumes and market liquidity. The 0x project, a protocol for building decentralized exchanges with interchangeable liquidity attempts to solve this issue.',\n",
       "  247),\n",
       " ('Decentralized finance',\n",
       "  'Drawbacks',\n",
       "  'Due to a lack of KYC processes, and no way to revert a transaction, users are at a loss if they are ever hacked for their passwords or private keys.Additionally, users staking in DeFi protocols can suffer what is called an impermanent loss.\\nAlthough liquidity pool DEX are the most widely used, they may have some drawbacks. The most common problems of liquidity pool DEXes are price slippage and front running.\\nPrice slippage occurs because of the AMM (Automated Market Makers) nature itself — the larger the deal, the stronger impact it has on the price. For example, if the constant product AMM is in use, every deal must keep the product xy = k constant, where x and y are quantities of two cryptocurrencies (or tokens) in the pool. So the larger is the input amount Δx, the lower is the final ratio y / x that gives an exchange price. The problem is mostly significant for large deals or small liquidity pools.\\nFront running is a special type of attack in public blockchains when some participant (usually a miner) seeing an upcoming trading transaction puts his own transaction ahead (playing with a transaction fee for example), making the initial transaction less profitable or even reverted. \\nIdeas of improving front running resistance of the constant product AMM were first discussed in a post by Vitalik Buterin.',\n",
       "  286),\n",
       " ('Decentralized finance',\n",
       "  'Degrees of decentralization',\n",
       "  'A decentralized exchange can still have centralized components, whereby some control of the exchange is still in the hands of a central authority. A notable example being IDEX blocking New York State users from placing orders on the platform.In July 2018, decentralized exchange Bancor was reportedly hacked and suffered a loss of $13.5M in assets before freezing funds. In a Tweet, Charlie Lee, the creator of Litecoin spoke out and claimed an exchange cannot be decentralized if it can lose or freeze customer funds.Operators of decentralized exchanges can face legal consequences from government regulators. One example is the founder of EtherDelta, who in November 2018 settled charges with the U.S. Securities and Exchange Commission over operating an unregistered securities exchange.Uniswap, which is built upon the Ethereum blockchain, has the largest trading volume of any DEX. It deployed its V3 to the Ethereum mainnet on May 5th 2021.',\n",
       "  190),\n",
       " ('Decentralized finance',\n",
       "  'Errors and hacking',\n",
       "  'Coding errors and hacks are common in DeFi. Blockchain transactions are irreversible, which means that an incorrect or fraudulent DeFi transaction cannot be corrected easily. For example, in 2020, a platform known as Yam Finance took deposits equivalent to $750 million within days of its launch before crashing because of a coding error. Additionally, the code for the smart contracts is generally open-source software that can be copied to set up competing platforms, which creates instabilities as funds shift from platform to platform.The person or entity behind a DeFi protocol may be unknown, and may disappear with investors\\' money. Investor Michael Novogratz has described some DeFi protocols as \"Ponzi-like\".DeFi has been compared to the initial coin offering craze of 2017, part of a cryptocurrency bubble. Inexperienced investors are at particular risk of losing money because of the sophistication required to interact with DeFi platforms and the lack of any intermediary with customer support.In 2021, half of cryptocurrency crime was related to DeFi. This rise has been attributed to a combination of developer incompetence and non-existent or poorly enforced regulations. Theft from DeFi can come from either external hackers stealing from vulnerable projects, or \"rug pulls\", where the developers and influencers promote a project and then take the money, as a form of pump-and-dump.',\n",
       "  275)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_sections(pages[0].content, pages[0].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544fe9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
